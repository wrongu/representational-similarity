import torch
import numpy as np
from repsim.geometry.hypersphere import HyperSphere
from repsim.geometry.stats import IterativeFrechetMean
from sklearn.base import BaseEstimator
from sklearn.manifold import MDS
from sklearn.utils import check_random_state
from joblib import Parallel, delayed, effective_n_jobs
import warnings


def _spherical_mds_single(distances,
                          *,
                          dim=2,
                          init=None,
                          max_iter=300,
                          eps=1e-3,
                          random_state=None):
    """Run a single instance of Spherical MDS, solving positions of n points on the dim-dimensional sphere (embedded
    in dim+1-dimensional space), using the algorithm from [1].

    [1] Agarwal, A., Phillips, J. M., & Venkatasubramanian, S. (2010). Universal multi-dimensional scaling. Proceedings
        of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 1149â€“1158.
        https://doi.org/10.1145/1835804.1835948
    """
    random_state = check_random_state(random_state)
    n_samples = distances.shape[0]

    def _project(z_):
        return z_ / torch.sqrt(torch.sum(z_ * z_, dim=-1, keepdim=True))

    # Initialize with Euclidean MDS, then project onto sphere
    if init is None:
        euclidean_mds = MDS(n_components=dim+1, n_init=1, dissimilarity="precomputed", random_state=random_state)
        z = torch.tensor(euclidean_mds.fit_transform(distances))
        z = _project(z - torch.mean(z, dim=0))
    else:
        assert init.shape == (n_samples, dim+1)
        z = _project(init - torch.mean(init, dim=0))

    def _angles(z_):
        return torch.arccos(torch.clip(torch.einsum('ia,ja->ij', z_, z_), -1.0, +1.0))

    def _squared_stress(z_):
        return torch.sum((torch.triu(distances) - torch.triu(_angles(z_))) ** 2)

    # Iteratively adjust one point at a time using Agarwal et al' algorithm
    sphere = HyperSphere(dim=dim)
    sq_stress = _squared_stress(z)
    for itr in range(max_iter):
        for i in torch.randperm(n_samples):
            mean_calculator = IterativeFrechetMean(sphere)
            # For each z_j, draw an arc from z_j to z_i and find the point along that line that is the 'correct'
            # distance away. Call it hat_z_j
            for j in torch.randperm(n_samples):
                if i == j: continue
                # Ratio of distance-we-want to distance-we-have
                ratio = distances[i, j] / sphere.length(z[i], z[j])
                # Find the point along the j-->i geodesic that is at the correct distance
                hat_z_j = sphere.exp_map(z[j], sphere.log_map(z[j], z[i]) * ratio)
                # Average together all hat_z_j's
                mean_calculator.update(hat_z_j)
            z[i] = mean_calculator.mean
        new_sq_stress = _squared_stress(z)

        if sq_stress - new_sq_stress < eps:
            # Converged!
            return z, torch.sqrt(new_sq_stress), itr
        else:
            sq_stress = new_sq_stress
    return z, torch.sqrt(sq_stress), max_iter-1


def spherical_mds(distances,
                  *,
                  dim=2,
                  init=None,
                  n_init=4,
                  n_jobs=None,
                  max_iter=300,
                  eps=1e-3,
                  random_state=None,
                  verbose=0,
                  return_n_iter=False):
    random_state = check_random_state(random_state)

    best_z, best_stress, best_iter = None, None, None

    if effective_n_jobs(n_jobs) == 1:
        for it in range(n_init):
            pos, stress, n_iter_ = _spherical_mds_single(
                distances,
                dim=dim,
                init=init,
                max_iter=max_iter,
                eps=eps,
                random_state=random_state,
            )
            if best_stress is None or stress < best_stress:
                best_stress = stress
                best_z = pos.clone()
                best_iter = n_iter_
    else:
        seeds = random_state.randint(np.iinfo(np.int32).max, size=n_init)
        results = Parallel(n_jobs=n_jobs, verbose=max(verbose - 1, 0))(
            delayed(_spherical_mds_single)(
                distances,
                dim=dim,
                init=init,
                max_iter=max_iter,
                eps=eps,
                random_state=seed,
            )
            for seed in seeds
        )
        positions, stress, n_iters = zip(*results)
        best = np.argmin(stress)
        best_stress = stress[best]
        best_z = positions[best]
        best_iter = n_iters[best]

    if return_n_iter:
        return best_z, best_stress, best_iter
    else:
        return best_z, best_stress


class SphericalMDS(BaseEstimator):
    """MultiDimensional Scaling on a sphere, in the style of sklearn.manifold.MDS.

    Note: backend is torch rather than numpy.
    """
    def __init__(
            self,
            dim=2,
            *,
            n_init=4,
            dissimilarity="arc length",
            center=False,
            max_iter=300,
            verbose=0,
            eps=1e-3,
            n_jobs=None,
            random_state=None):
        self.dim = dim
        self.n_init = n_init
        self.dissimilarity = dissimilarity.lower()
        self.center = center
        self.max_iter = max_iter
        self.verbose = verbose
        self.eps = eps
        self.n_jobs = n_jobs
        self.random_state = random_state

    def fit(self, X, y=None, init=None):
        self.fit_transform(X, y, init=init)
        return self

    def fit_transform(self, X, y=None, init=None):
        if y is not None:
            warnings.warn("SphericalMDS does not use 'y' argument")

        if self.dissimilarity == "precomputed":
            if not _is_arc_length_matrix(X):
                raise ValueError("With dissimilarity='precomputed', X must be a valid matrix of pairwise arc-distances.")
            self.dissimilarity_matrix_ = X
        elif self.dissimilarity == "arc length":
            self.dissimilarity_matrix_ = pairwise_arc_lengths(X, self.center)
        else:
            raise ValueError("'dissimilarity' argument must be one of 'arc length' or 'precomputed'")

        self.embedding_, self.stress_, self.n_iter_ = spherical_mds(
            self.dissimilarity_matrix_,
            dim=self.dim,
            init=init,
            n_init=self.n_init,
            n_jobs=self.n_jobs,
            max_iter=self.max_iter,
            eps=self.eps,
            random_state=self.random_state,
            return_n_iter=True,
        )
        return self.embedding_


def pairwise_arc_lengths(X, center):
    # TODO - implement batch-wise and pair-wise operations natively in HyperSphere (and other spaces)
    if center:
        X = X - torch.mean(X, 0)
    dot_ij = X @ X.T
    len_ii = torch.sqrt(torch.diag(dot_ij))
    cosine = dot_ij / len_ii[:, None] / len_ii[None, :]
    return torch.arccos(torch.clip(cosine, -1.0, +1.0))


def _is_arc_length_matrix(X):
    if X.ndim != 2:
        return False
    if X.shape[0] != X.shape[1]:
        return False
    if not torch.all(X >= 0.) or not torch.all(X <= torch.pi):
        return False
    if not torch.allclose(torch.diag(X), torch.zeros(X.shape[:1])):
        return False
    return True
